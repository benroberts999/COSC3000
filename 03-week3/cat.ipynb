{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bivariate Examples:\n",
    " * Correlation\n",
    " * Regression and fitting curves\n",
    " * Confidence intervals\n",
    "\n",
    "Use Cat Retina data \"catretina.csv\" [Lia _et al._, Science (1987)](https://www.science.org/doi/10.1126/science.3576202)\n",
    "* We'll consider 'cpRatio' as a function of 'retinarea' for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and plot the data\n",
    "* several columns. We use 'retinarea' as the independent variably (x axis), and 'cpRatio' as the dependent variable (y axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"catretina.csv\"\n",
    "data = np.genfromtxt(filename, delimiter=\",\", names=True, skip_header=1)\n",
    "collumns = list(data.dtype.names)\n",
    "\n",
    "print(collumns)\n",
    "\n",
    "xdata = data[\"retinarea\"]\n",
    "ydata = data[\"cpRatio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coeficient\n",
    "\n",
    "Simple test: are the data correlated?\n",
    "\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson = stats.pearsonr(xdata, ydata)\n",
    "print(\n",
    "    f\"Pearson correlation coef: {pearson.statistic:.3f}, p-value: {pearson.pvalue:.2e}\"\n",
    ")\n",
    "\n",
    "spearman = stats.spearmanr(xdata, ydata)\n",
    "print(\n",
    "    f\"Pearson correlation coef: {spearman.statistic:.3f}, p-value: {spearman.pvalue:.2e}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit polynomial\n",
    "* Fit linear, quadratic, cubic polynomials\n",
    "* plot\n",
    "* nb: I'm using the older library: https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html\n",
    "* There's a newer one: https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs1 = np.polyfit(xdata, ydata, 1)\n",
    "coefs2 = np.polyfit(xdata, ydata, 2)\n",
    "coefs3 = np.polyfit(xdata, ydata, 3)\n",
    "\n",
    "# Takes the coefs from the fit, and creates callable polynomial functions\n",
    "y1 = np.poly1d(coefs1)\n",
    "y2 = np.poly1d(coefs2)\n",
    "y3 = np.poly1d(coefs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create denser x-grid for plotting\n",
    "x = np.linspace(min(xdata), max(xdata), 100)\n",
    "\n",
    "plt.plot(data[\"retinarea\"], data[\"cpRatio\"], \"bx\")\n",
    "plt.plot(x, y1(x), label=\"linear\")\n",
    "plt.plot(x, y2(x), label=\"quadratic\")\n",
    "plt.plot(x, y3(x), label=\"cubic\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = ydata - y1(xdata)\n",
    "\n",
    "\n",
    "plt.plot(xdata, res1, \"bx\")\n",
    "plt.title(\"Linear-fit residuals\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio residuals (linear)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = ydata - y2(xdata)\n",
    "\n",
    "plt.plot(xdata, res2, \"bx\")\n",
    "plt.title(\"Quadratic-fit residuals\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio residuals (quadratic)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define R^2\n",
    "\n",
    "$$\n",
    "  R^2 = 1 - \\frac{SS_{\\rm res}}{SStot}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "  SS_{\\rm res} = \\sum_i [y_i - y(x_i)]^2\n",
    "$$\n",
    "\n",
    "is the sum of square residuals is, and\n",
    "\n",
    "$$\n",
    "  SS_{\\rm tot} = \\sum_i [y_i - \\bar y]^2.\n",
    "$$\n",
    "\n",
    "* $y_i$ is the $i^{\\rm th}$ observed $y$ value (data point)\n",
    "* $x_i$ is the $i^{\\rm th}$ observed $x$ value (data point)\n",
    "* $y$ is the best-fit function\n",
    "* $\\bar y$ is the mean of the observed $y$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(f, ydata, xdata):\n",
    "    SSres = np.sum((ydata - f(xdata)) ** 2)\n",
    "    SStot = np.sum((ydata - np.mean(ydata)) ** 2)\n",
    "    return 1.0 - SSres / SStot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_1, r2_2, r2_3 = [R2(f, ydata, xdata) for f in [y1, y2, y3]]\n",
    "\n",
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.plot(x, y1(x), label=f\"$R^2 = {r2_1:.4g}$\")\n",
    "plt.plot(x, y2(x), label=f\"$R^2 = {r2_2:.4g}$\")\n",
    "plt.plot(x, y3(x), label=f\"$R^2 = {r2_3:.4g}$\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beware of over-fitting\n",
    "\n",
    "* One way is to instead optimse the _modified_ least squares\n",
    "\n",
    "$$\n",
    "  SS_{{\\rm res},M} = \\sum_i \\frac{[y_i - y(x_i)]^2}{N - 2M}\n",
    "$$\n",
    "\n",
    "  * $N$ is the number of data points\n",
    "  * $M$ is the number of parameters (e.g., $m=2$ for linear, 3 for quadratic, 4 for cubic)\n",
    "\n",
    "* General rule: use as _few_ parameters as you can, never more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs6 = np.polyfit(xdata, ydata, 6)\n",
    "y6 = np.poly1d(coefs6)\n",
    "r2_6 = R2(y6, ydata, xdata)\n",
    "\n",
    "SSm1 = np.sum((ydata - y1(xdata)) ** 2) / (len(xdata) - 2 * 2)\n",
    "SSm2 = np.sum((ydata - y2(xdata)) ** 2) / (len(xdata) - 2 * 3)\n",
    "SSm3 = np.sum((ydata - y3(xdata)) ** 2) / (len(xdata) - 2 * 4)\n",
    "SSm8 = np.sum((ydata - y6(xdata)) ** 2) / (len(xdata) - 2 * 6)\n",
    "\n",
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.plot(x, y1(x), label=f\"$R^2 = {r2_1:.4g}, SS_m = {SSm1:.2g}$\")\n",
    "plt.plot(x, y2(x), label=f\"$R^2 = {r2_2:.4g}, SS_m = {SSm2:.2g}$\")\n",
    "plt.plot(x, y3(x), label=f\"$R^2 = {r2_3:.4g}, SS_m = {SSm3:.2g}$\")\n",
    "plt.plot(x, y6(x), label=f\"$R^2 = {r2_6:.4g}, SS_m = {SSm8:.2g}$\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beware extrapolting\n",
    "\n",
    "* Polynomials are very unstable for large arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.linspace(0, 200, 100)\n",
    "\n",
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.plot(x2, y1(x2), label=f\"linear\")\n",
    "plt.plot(x2, y2(x2), label=f\"quadratic\")\n",
    "plt.plot(x2, y3(x2), label=f\"cubic\")\n",
    "plt.plot(x2, y6(x2), label=f\"order 6\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 40)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------\n",
    "## Significance, T-test, etc.\n",
    "\n",
    "If the standard deviation of the population is not well known, it's common to use a student t distribution instead of a Gaussian:\n",
    "* https://en.wikipedia.org/wiki/Student%27s_t-distribution\n",
    "\n",
    "If in the null hyposesis, the mean of our observations would be expected to be 0,\n",
    "we form the t-statistic:\n",
    "$$\n",
    "  t = \\frac{\\bar x}{\\sigma_{\\bar x}}\n",
    "$$\n",
    "\n",
    "where \n",
    "* $\\bar x$ is the observed mean\n",
    "* $\\sigma_{\\bar x} = \\sigma_{x} / \\sqrt{N}$ is the _standard error_ in the mean\n",
    "* $\\sigma_{x}$ is the (unbiased/corrected) sample standard deviation of observed $x$\n",
    "* $N$ is the number of observations\n",
    "\n",
    "We wish to know:\n",
    "\n",
    " * For a given $t$ what is the significance (i.e., what is the $p$ value)\n",
    " * For a given $p$ value/significance, what $t$ score is required\n",
    "\n",
    "This depends on the degrees of freedom\n",
    " * d.o.f = number of data points, minus number of fit parameters\n",
    " * As d.o.f gets large, approaches Gaussian\n",
    "\n",
    "See:\n",
    "\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html\n",
    "\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Student%27s_t-distribution#Table_of_selected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html\n",
    "\n",
    "\n",
    "# Given a target p value, finds the required t score:\n",
    "def find_t(p_target, dof):\n",
    "    \"\"\"Returns the t value required to achieve p value of p_target,\n",
    "    given dof degrees of freedom (dof = N_data - N_params)\"\"\"\n",
    "    return np.abs(stats.t.ppf(0.5 * p_target, dof))\n",
    "\n",
    "\n",
    "# Given a t-score, finds the p-value\n",
    "def find_p(t, dof):\n",
    "    \"\"\"Returns the p value, given the t value\"\"\"\n",
    "    return 2 * (1 - np.abs(stats.t.cdf(t, dof)))\n",
    "\n",
    "\n",
    "# Compare to: https://en.wikipedia.org/wiki/Student%27s_t-distribution#Table_of_selected_values\n",
    "print(\"Table of t values for the 85%, 95%, and 99% confidence levels\")\n",
    "print(\"  dof   t(80%)  t(95%)  t(95%)\")\n",
    "for dof in [10, 20, 50, 100, 120, 10000]:\n",
    "    print(\n",
    "        f\"{dof:5d}   {find_t(0.2, dof):.3f}   {find_t(0.05, dof):.3f}   {find_t(0.01, dof):.3f}\"\n",
    "    )\n",
    "\n",
    "# Example\n",
    "print()\n",
    "print(\"For example, our cat data in linear model:\")\n",
    "n_data = len(xdata)\n",
    "num_params = 3\n",
    "degrees_of_freedom = n_data - num_params\n",
    "\n",
    "tcat = find_t(0.05, degrees_of_freedom)\n",
    "print(f\"cat data: We require t={tcat:.2f} for a 95% C.L.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Linear regression\n",
    "\n",
    "* In the simples (linear) case 'linregress' method does it all for us\n",
    "* Calculates best-fit slope + intercept, with uncertainties, and p-values etc:\n",
    "* nb: p value alone not very meaningful here\n",
    "\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = stats.linregress(xdata, ydata)\n",
    "print(\"R=\", linreg.rvalue, \"p=\", linreg.pvalue)\n",
    "print(\"b=\", linreg.intercept, \"b_err=\", linreg.intercept_stderr)\n",
    "print(\"m=\", linreg.slope, \"m_err=\", linreg.stderr)\n",
    "\n",
    "t = linreg.rvalue * np.sqrt((len(xdata) - 2) / (1 - linreg.rvalue**2))\n",
    "\n",
    "\n",
    "print(\"Manual t score: \", t)\n",
    "print(\"Manual p value: \", find_p(t, len(xdata) - 2))\n",
    "\n",
    "best = linreg.intercept + linreg.slope * x\n",
    "\n",
    "\n",
    "# Error in line y = a + b*x, given error in a and b:\n",
    "def err(x, da, db):\n",
    "    return np.sqrt(da**2 + (db * x) ** 2)\n",
    "\n",
    "\n",
    "# The (standard) uncertainty in y\n",
    "dy1 = err(x, linreg.intercept_stderr, linreg.stderr)\n",
    "\n",
    "# t value at 95% and 99% confidence level:\n",
    "# Note: these differ only slightly from Gaussian values.\n",
    "# It's fine to just use the 68/95/99.7 rule\n",
    "t_95 = find_t(0.05, len(xdata) - 2)\n",
    "t_99 = find_t(0.01, len(xdata) - 2)\n",
    "\n",
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.plot(x, best, \"r-\", label=\"best fit\")\n",
    "plt.plot(x, best + dy1, \"k-\", label=\"Standard error\")\n",
    "plt.plot(x, best - dy1, \"k-\")\n",
    "plt.plot(x, best + t_95 * dy1, \"--\", c=\"grey\", label=\"95% confidence\")\n",
    "plt.plot(x, best - t_95 * dy1, \"--\", c=\"grey\")\n",
    "plt.plot(x, best + t_99 * dy1, ls=\"dotted\", c=\"lightgrey\", label=\"99% confidence\")\n",
    "plt.plot(x, best - t_99 * dy1, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More general method: use curve_fit\n",
    "\n",
    "* Fits _any_ function (not just a polynomaial) to data using least squares\n",
    "* optionally include weights for the fit\n",
    "\n",
    "Returns the set of fit parameters `popt`, and covariance matrix `pcov`\n",
    "* The diagonal entries in the covariance matrix are approximately the variances in the best-fit parameters\n",
    "* e.g., for parameters a, b, c, ... get their (standard, 1sigma) uncertainties:\n",
    "* `da, db, dc = np.sqrt(np.diag(pcov))`\n",
    "\n",
    "See:\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_linear(x, a, b):\n",
    "    return a + b * x\n",
    "\n",
    "\n",
    "# perform the fit:\n",
    "popt, pcov = curve_fit(f_linear, xdata, ydata)\n",
    "\n",
    "# extract the parameters from 'popt = optimised paramters' (careful of the order)\n",
    "a, b = popt\n",
    "\n",
    "# Extract the _approximate_ (1 sigma = standard) uncertainties from pcov (parameter covariance)\n",
    "da, db = np.sqrt(np.diag(pcov))\n",
    "\n",
    "\n",
    "def df(x, da, db):\n",
    "    return np.sqrt(da**2 + (db * x) ** 2)\n",
    "\n",
    "\n",
    "# t scores required for 95, 99 % confidence levels\n",
    "# Note: these differ only slightly from Gaussian values\n",
    "t_95 = find_t(0.05, len(xdata) - 2)\n",
    "t_99 = find_t(0.01, len(xdata) - 2)\n",
    "\n",
    "# Best fit and error in fit:\n",
    "best = f_linear(x, a, b)\n",
    "error = df(x, da, db)\n",
    "\n",
    "\n",
    "print(\"Roughly: t = \", b / db)\n",
    "\n",
    "plt.title(f\"Linear Fit: $y = a + bx$\")\n",
    "plt.text(10, 12, f\"$a={a:.3f}\\\\pm{da:.3f}$\\n$b={b:.3f}\\\\pm{db:.3f}$\")\n",
    "\n",
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.plot(x, best, \"r-\", label=\"best fit\")\n",
    "\n",
    "# Plot standard errors:\n",
    "plt.plot(x, best + error, \"k-\", label=\"Standard error\")\n",
    "plt.plot(x, best - error, \"k-\")\n",
    "\n",
    "# Confidence intervals\n",
    "plt.plot(x, best + t_95 * error, c=\"grey\", ls=\"dashed\", label=\"95% C.L.\")\n",
    "plt.plot(x, best - t_95 * error, c=\"grey\", ls=\"dashed\")\n",
    "plt.plot(x, best + t_99 * error, ls=\"dotted\", c=\"lightgrey\", label=\"99% confidence\")\n",
    "plt.plot(x, best - t_99 * error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... and for a quadratic fit\n",
    "\n",
    "* Note: uncertainty in Y(x) for the fit becomes less meaningful\n",
    "* Calculation assumes uncertainty in coeficients is independent\n",
    "    * this is certainly not true!\n",
    "* Proper statistics is hard, this is OK as a start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_quad(x, a, b, c):\n",
    "    return a + b * x + c * x**2\n",
    "\n",
    "\n",
    "# perform the fit:\n",
    "popt, pcov = curve_fit(f_quad, xdata, ydata)\n",
    "\n",
    "# extract the parameters from 'popt = optimised paramters' (careful of the order)\n",
    "a, b, c = popt\n",
    "\n",
    "# Extract the _approximate_ (1 sigma = standard) uncertainties from pcov (parameter covariance)\n",
    "da, db, dc = np.sqrt(np.diag(pcov))\n",
    "\n",
    "\n",
    "# Uncertainty in f(x), given uncertainty in paramaters [just add in quadrature]\n",
    "# nb: assumes independent, not really true!\n",
    "def df(x, da, db, dc):\n",
    "    return np.sqrt(da**2 + (db * x) ** 2 + (dc * x**2) ** 2)\n",
    "\n",
    "\n",
    "best = f_quad(x, a, b, c)\n",
    "error = df(x, da, db, dc)\n",
    "\n",
    "# t values, now with 3 parameters\n",
    "t_95 = find_t(0.05, len(xdata) - 3)\n",
    "t_99 = find_t(0.01, len(xdata) - 3)\n",
    "\n",
    "plt.title(\"Fit: $y = a + bx + cx^2$\")\n",
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.plot(x, best, \"r-\", label=\"best fit\")\n",
    "plt.text(\n",
    "    10, 15, f\"$a={a:.2f}\\\\pm{da:.2f}$\\n$b={b:.3f}\\\\pm{db:.3f}$\\n$c={c:.2g}\\\\pm{dc:.2g}$\"\n",
    ")\n",
    "# 1 sigma (standard) errors:\n",
    "plt.plot(x, best + error, \"k-\", label=\"Standard error\")\n",
    "plt.plot(x, best - error, \"k-\")\n",
    "# Confidence intervals\n",
    "plt.plot(x, best + t_95 * error, c=\"grey\", ls=\"dashed\", label=\"95% C.L.\")\n",
    "plt.plot(x, best - t_95 * error, c=\"grey\", ls=\"dashed\")\n",
    "plt.plot(x, best + t_99 * error, ls=\"dotted\", c=\"lightgrey\", label=\"99% confidence\")\n",
    "plt.plot(x, best - t_99 * error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with fill_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Fit: $y = a + bx + cx^2$\")\n",
    "plt.plot(xdata, ydata, \"bx\")\n",
    "plt.plot(x, best, \"r-\", label=\"best fit\")\n",
    "plt.text(\n",
    "    10, 15, f\"$a={a:.2f}\\\\pm{da:.2f}$\\n$b={b:.3f}\\\\pm{db:.3f}$\\n$c={c:.2g}\\\\pm{dc:.2g}$\"\n",
    ")\n",
    "# 1 sigma (standard) errors:\n",
    "plt.plot(x, best + error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.plot(x, best - error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.plot(x, best + t_95 * error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.plot(x, best - t_95 * error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.plot(x, best + t_99 * error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.plot(x, best - t_99 * error, ls=\"dotted\", c=\"lightgrey\")\n",
    "plt.fill_between(x, best + error, best - error, color=\"red\", alpha=0.4, label=\"Error\")\n",
    "plt.fill_between(\n",
    "    x, best + t_95 * error, best - t_95 * error, color=\"red\", alpha=0.25, label=\"95%\"\n",
    ")\n",
    "plt.fill_between(\n",
    "    x, best + t_99 * error, best - t_99 * error, color=\"red\", alpha=0.1, label=\"99%\"\n",
    ")\n",
    "plt.xlabel(\"Retina area (mm$^2$)\")\n",
    "plt.ylabel(\"CP ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
